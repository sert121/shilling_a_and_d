# -*- coding: utf-8 -*-
"""Supervised_detection_methods[BASELINE].ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1C5fIoHFNDtI6XbM1aosCkIhOEqV4hepn
"""

"""
Link to drive folder: 
"""
from google.colab import drive
drive.mount('/content/drive')

#write a logistic regression functoin scikit learn
import pandas as pd
import seaborn as sns
import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix
from sklearn.metrics import classification_report
from sklearn.metrics import accuracy_score
#import Ridge classifier,SVM
from sklearn.linear_model import RidgeClassifier
from sklearn.linear_model import SGDClassifier
from sklearn import svm
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import GaussianNB

def sgd_classifier(X, y,img_name="def"):
    '''
    X is a numpy.ndarray of shape (n, d) containing the dataset
    y is a numpy.ndarray of shape (n, 1) containing the labels of the data
    '''
    # split the data into training and testing sets
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4,
                                                        random_state=0,shuffle=True)
    # instantiate the model
    sgd = SGDClassifier()
    # fit the model
    sgd.fit(X_train, y_train.ravel())
    # predict the labels of the testing set
    y_pred = sgd.predict(X_test)
    # calculate the accuracy of the model
    accuracy = accuracy_score(y_test, y_pred)
    # print the accuracy of the model
    print("Accuracy: {:.2f}%".format(accuracy*100))
    # print the confusion matrix
    print(confusion_matrix(y_test, y_pred))
    conf_mat = confusion_matrix(y_test, y_pred)
    # sns.heatmap(conf_mat, square=True, annot=True, cmap='Blues', fmt='d', cbar=False)
    # sns_plot.figure.savefig(f"sgd_classifier_conf_matrix_{img_name}.png")    
    # print the classification report
    # print(classification_report(y_test, y_pred))
    return None

''' import Logistic Regression and fit a model'''
def logistic_regression(X, y,img_name="def"):
    '''
    X is a numpy.ndarray of shape (n, d) containing the dataset
    y is a numpy.ndarray of shape (n, 1) containing the labels of the data
    '''
    # split the data into training and testing sets
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4,
                                                        random_state=0,shuffle=True)
    # instantiate the model
    logreg = LogisticRegression()
    # fit the model
    logreg.fit(X_train, y_train.ravel())
    # predict the labels of the testing set
    y_pred = logreg.predict(X_test)
    # calculate the accuracy of the model
    accuracy = accuracy_score(y_test, y_pred)
    # print the accuracy of the model
    print("Accuracy: {:.2f}%".format(accuracy*100))
    # print the confusion matrix
    print(confusion_matrix(y_test, y_pred))
    conf_mat = confusion_matrix(y_test, y_pred)
    # sns.heatmap(conf_mat, square=True, annot=True, cmap='Blues', fmt='d', cbar=False)
    # sns_plot.figure.savefig(f"logistic_reg_conf_matrix_{img_name}.png")
    # print the classification report
    # print(classification_report(y_test, y_pred))
    return None

'''import SVM model and fit a model'''
def svm_classifier(X, y,img_name="def"):
    '''
    X is a numpy.ndarray of shape (n, d) containing the dataset
    y is a numpy.ndarray of shape (n, 1) containing the labels of the data
    '''
    # split the data into training and testing sets
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4,
                                                        random_state=0,shuffle=True)
    # instantiate the model
    svm1 = svm.SVC()
    # fit the model
    svm1.fit(X_train, y_train.ravel())
    # predict the labels of the testing set
    y_pred = svm1.predict(X_test)
    # calculate the accuracy of the model
    accuracy = accuracy_score(y_test, y_pred)
    # print the accuracy of the model
    print("Accuracy: {:.2f}%".format(accuracy*100))
    # print the confusion matrix
    print(confusion_matrix(y_test, y_pred))
    conf_mat = confusion_matrix(y_test, y_pred)
    # sns.heatmap(conf_mat, square=True, annot=True, cmap='Blues', fmt='d', cbar=False)
    # sns_plot.figure.savefig(f"svm1_conf_matrix_{img_name}.png")

    # print the classification report
    # print(classification_report(y_test, y_pred))
    return None

''' import and fit a random forest classifier  from sklearn'''
def random_forest(X, y,img_name="def"):
    '''
    X is a numpy.ndarray of shape (n, d) containing the dataset
    y is a numpy.ndarray of shape (n, 1) containing the labels of the data
    '''
    # split the data into training and testing sets
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4,shuffle=True,
                                                        random_state=0)
    # instantiate the model
    rf = RandomForestClassifier(n_estimators=10)
    # fit the model
    rf.fit(X_train, y_train.ravel())
    # predict the labels of the testing set
    y_pred = rf.predict(X_test)
    # calculate the accuracy of the model
    accuracy = accuracy_score(y_test, y_pred)
    # print the accuracy of the model
    print("Accuracy: {:.2f}%".format(accuracy*100))
    # print the confusion matrix
    print(confusion_matrix(y_test, y_pred))
    conf_mat = confusion_matrix(y_test, y_pred)
    # sns.heatmap(conf_mat, square=True, annot=True, cmap='Blues', fmt='d', cbar=False)
    # sns_plot.figure.savefig(f"random_forest_conf_matrix_{img_name}.png")
    # print the classification report
    # print(classification_report(y_test, y_pred))
    return None

'''import and fit K-nearest neighbours classifier from sklearn'''
def knn_classifier(X, y,img_name="def"):
    '''
    X is a numpy.ndarray of shape (n, d) containing the dataset
    y is a numpy.ndarray of shape (n, 1) containing the labels of the data
    '''
    # split the data into training and testing sets
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4,
                                                        random_state=0,shuffle=True)
    # instantiate the model
    knn = KNeighborsClassifier(n_neighbors=5)
    # fit the model
    knn.fit(X_train, y_train.ravel())
    # predict the labels of the testing set
    y_pred = knn.predict(X_test)
    # calculate the accuracy of the model
    accuracy = accuracy_score(y_test, y_pred)
    # print the accuracy of the model
    print("Accuracy: {:.2f}%".format(accuracy*100))
    # print the confusion matrix
    print(confusion_matrix(y_test, y_pred))
    # conf_mat = confusion_matrix(y_test, y_pred)
    # sns.heatmap(conf_mat, square=True, annot=True, cmap='Blues', fmt='d', cbar=False)
    # sns_plot.figure.savefig(f"knn_conf_matrix_{img_name}.png")

    # print the classification report
    # print(classification_report(y_test, y_pred))
    return True

'''import and fit Gaussian Naive bayes model'''
def gaussian_naive_bayes(X, y,img_name="def"):
    '''
    X is a numpy.ndarray of shape (n, d) containing the dataset
    y is a numpy.ndarray of shape (n, 1) containing the labels of the data
    '''
    # split the data into training and testing sets
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4,
                                                        random_state=0,shuffle=True)
    # instantiate the model
    gnb = GaussianNB()
    # fit the model
    gnb.fit(X_train, y_train.ravel())
    # predict the labels of the testing set
    y_pred = gnb.predict(X_test)
    # calculate the accuracy of the model
    accuracy = accuracy_score(y_test, y_pred)
    # print the accuracy of the model
    print("Accuracy: {:.2f}%".format(accuracy*100))
    # print the confusion matrix
    conf_mat = confusion_matrix(y_test, y_pred)
    # sns.heatmap(conf_mat, square=True, annot=True, cmap='Blues', fmt='d', cbar=False)
    # sns_plot.figure.savefig(f"gaussian_naive_conf_matrix_{img_name}.png")
    # print the classification report
    # print(classification_report(y_test, y_pred))
    return None

def load_data(file1,file2):
  names = ['user_id', 'item_id', 'rating', 'timestamp']
  data= pd.read_csv(file1,delim_whitespace=True,names=names)
  data2 = pd.read_csv(file2,delim_whitespace=True,names=names)
  return data,data2

# change file location according to attack type and size
names = ['user_id', 'item_id', 'rating', 'timestamp']
ratings=pd.read_csv("/content/drive/MyDrive/attack_datasets/Movielens1M/random/random_profiles_1.0.txt",delim_whitespace=True,names=names)
names1=['user_id','label']
labels=pd.read_csv("/content/drive/MyDrive/attack_datasets/Movielens1M/random/random_labels_1.0.txt",delim_whitespace=True,names=names1)

# data matrix, timestamp matrix
n_users = ratings.user_id.unique().shape[0]
n_items = ratings.item_id.unique().shape[0]
n_items = ratings['item_id'].max()
data_matrix = np.zeros((n_users,n_items))
#timestamp_matrix=np.zeros((n_users,n_items))
for line in ratings.itertuples():
    data_matrix[line[1]-1,line[2]-1] = line[3]
    #timestamp_matrix[line[1]-1,line[2]-1] = line[4]
print("Original rating matrix : ",data_matrix.shape)

'''
creating labels for genuine and attack profiles according to the attack percentage (10/15/20/25%)
'''
labels_new = [1 for i in range(0,6040)] + [0 for i in range((labels.shape[0]-1)-6040)]

y = labels_new
X = data_matrix

knn = knn_classifier(X,np.array(y),"knn")

logistic_regression(X,np.array(y))

svm_classifier(X,np.array(y))

random_forest(X,np.array(y))

sgd_classifier(X,np.array(y))

gaussian_naive_bayes(X,np.array(y))

from pandas import read_csv
from keras.models import Sequential
from keras.layers import Dense
from keras.layers import Dropout
from keras.wrappers.scikit_learn import KerasClassifier
from sklearn.model_selection import cross_val_score
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import StratifiedKFold
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline
import numpy as np
# load dataset
import pandas as pd
import random
from sklearn.model_selection import train_test_split


def create_MLP_baseline():
  # create model
  model = Sequential()
  model.add(Dense(400, input_dim=3952, activation='relu'))
  model.add(Dense(200,activation='relu'))
  model.add(Dropout(0.5))
  model.add(Dense(100, activation='relu'))
  model.add(Dropout(0.5))
  model.add(Dense(10))
  model.add(Dense(1, activation='sigmoid'))
  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
  return model

def pipeline(X,y):
  
    model = create_MLP_baseline()
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4,
                                                        random_state=0,shuffle=True)    
    history = model.fit(X_train,np.array(y_train),epochs=1)
    results = model.evaluate(X_test,np.array(y_test))
    return results[1]

pipeline(X,y)