{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Supervised_detection_methods[BASELINE].ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZTuvJ3azqZUP",
        "outputId": "4fc3e01c-0c84-45d9-d5ce-31c57b3f4abd"
      },
      "source": [
        "\"\"\"\n",
        "Link to drive folder: \n",
        "\"\"\"\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12O2adAvk1ON"
      },
      "source": [
        "#write a logistic regression functoin scikit learn\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import accuracy_score\n",
        "#import Ridge classifier,SVM\n",
        "from sklearn.linear_model import RidgeClassifier\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn import svm\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "def sgd_classifier(X, y,img_name=\"def\"):\n",
        "    '''\n",
        "    X is a numpy.ndarray of shape (n, d) containing the dataset\n",
        "    y is a numpy.ndarray of shape (n, 1) containing the labels of the data\n",
        "    '''\n",
        "    # split the data into training and testing sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4,\n",
        "                                                        random_state=0,shuffle=True)\n",
        "    # instantiate the model\n",
        "    sgd = SGDClassifier()\n",
        "    # fit the model\n",
        "    sgd.fit(X_train, y_train.ravel())\n",
        "    # predict the labels of the testing set\n",
        "    y_pred = sgd.predict(X_test)\n",
        "    # calculate the accuracy of the model\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    # print the accuracy of the model\n",
        "    print(\"Accuracy: {:.2f}%\".format(accuracy*100))\n",
        "    # print the confusion matrix\n",
        "    print(confusion_matrix(y_test, y_pred))\n",
        "    conf_mat = confusion_matrix(y_test, y_pred)\n",
        "    # sns.heatmap(conf_mat, square=True, annot=True, cmap='Blues', fmt='d', cbar=False)\n",
        "    # sns_plot.figure.savefig(f\"sgd_classifier_conf_matrix_{img_name}.png\")    \n",
        "    # print the classification report\n",
        "    # print(classification_report(y_test, y_pred))\n",
        "    return None\n",
        "\n",
        "''' import Logistic Regression and fit a model'''\n",
        "def logistic_regression(X, y,img_name=\"def\"):\n",
        "    '''\n",
        "    X is a numpy.ndarray of shape (n, d) containing the dataset\n",
        "    y is a numpy.ndarray of shape (n, 1) containing the labels of the data\n",
        "    '''\n",
        "    # split the data into training and testing sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4,\n",
        "                                                        random_state=0,shuffle=True)\n",
        "    # instantiate the model\n",
        "    logreg = LogisticRegression()\n",
        "    # fit the model\n",
        "    logreg.fit(X_train, y_train.ravel())\n",
        "    # predict the labels of the testing set\n",
        "    y_pred = logreg.predict(X_test)\n",
        "    # calculate the accuracy of the model\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    # print the accuracy of the model\n",
        "    print(\"Accuracy: {:.2f}%\".format(accuracy*100))\n",
        "    # print the confusion matrix\n",
        "    print(confusion_matrix(y_test, y_pred))\n",
        "    conf_mat = confusion_matrix(y_test, y_pred)\n",
        "    # sns.heatmap(conf_mat, square=True, annot=True, cmap='Blues', fmt='d', cbar=False)\n",
        "    # sns_plot.figure.savefig(f\"logistic_reg_conf_matrix_{img_name}.png\")\n",
        "    # print the classification report\n",
        "    # print(classification_report(y_test, y_pred))\n",
        "    return None\n",
        "\n",
        "'''import SVM model and fit a model'''\n",
        "def svm_classifier(X, y,img_name=\"def\"):\n",
        "    '''\n",
        "    X is a numpy.ndarray of shape (n, d) containing the dataset\n",
        "    y is a numpy.ndarray of shape (n, 1) containing the labels of the data\n",
        "    '''\n",
        "    # split the data into training and testing sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4,\n",
        "                                                        random_state=0,shuffle=True)\n",
        "    # instantiate the model\n",
        "    svm1 = svm.SVC()\n",
        "    # fit the model\n",
        "    svm1.fit(X_train, y_train.ravel())\n",
        "    # predict the labels of the testing set\n",
        "    y_pred = svm1.predict(X_test)\n",
        "    # calculate the accuracy of the model\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    # print the accuracy of the model\n",
        "    print(\"Accuracy: {:.2f}%\".format(accuracy*100))\n",
        "    # print the confusion matrix\n",
        "    print(confusion_matrix(y_test, y_pred))\n",
        "    conf_mat = confusion_matrix(y_test, y_pred)\n",
        "    # sns.heatmap(conf_mat, square=True, annot=True, cmap='Blues', fmt='d', cbar=False)\n",
        "    # sns_plot.figure.savefig(f\"svm1_conf_matrix_{img_name}.png\")\n",
        "\n",
        "    # print the classification report\n",
        "    # print(classification_report(y_test, y_pred))\n",
        "    return None\n",
        "\n",
        "''' import and fit a random forest classifier  from sklearn'''\n",
        "def random_forest(X, y,img_name=\"def\"):\n",
        "    '''\n",
        "    X is a numpy.ndarray of shape (n, d) containing the dataset\n",
        "    y is a numpy.ndarray of shape (n, 1) containing the labels of the data\n",
        "    '''\n",
        "    # split the data into training and testing sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4,shuffle=True,\n",
        "                                                        random_state=0)\n",
        "    # instantiate the model\n",
        "    rf = RandomForestClassifier(n_estimators=10)\n",
        "    # fit the model\n",
        "    rf.fit(X_train, y_train.ravel())\n",
        "    # predict the labels of the testing set\n",
        "    y_pred = rf.predict(X_test)\n",
        "    # calculate the accuracy of the model\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    # print the accuracy of the model\n",
        "    print(\"Accuracy: {:.2f}%\".format(accuracy*100))\n",
        "    # print the confusion matrix\n",
        "    print(confusion_matrix(y_test, y_pred))\n",
        "    conf_mat = confusion_matrix(y_test, y_pred)\n",
        "    # sns.heatmap(conf_mat, square=True, annot=True, cmap='Blues', fmt='d', cbar=False)\n",
        "    # sns_plot.figure.savefig(f\"random_forest_conf_matrix_{img_name}.png\")\n",
        "    # print the classification report\n",
        "    # print(classification_report(y_test, y_pred))\n",
        "    return None\n",
        "\n",
        "'''import and fit K-nearest neighbours classifier from sklearn'''\n",
        "def knn_classifier(X, y,img_name=\"def\"):\n",
        "    '''\n",
        "    X is a numpy.ndarray of shape (n, d) containing the dataset\n",
        "    y is a numpy.ndarray of shape (n, 1) containing the labels of the data\n",
        "    '''\n",
        "    # split the data into training and testing sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4,\n",
        "                                                        random_state=0,shuffle=True)\n",
        "    # instantiate the model\n",
        "    knn = KNeighborsClassifier(n_neighbors=5)\n",
        "    # fit the model\n",
        "    knn.fit(X_train, y_train.ravel())\n",
        "    # predict the labels of the testing set\n",
        "    y_pred = knn.predict(X_test)\n",
        "    # calculate the accuracy of the model\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    # print the accuracy of the model\n",
        "    print(\"Accuracy: {:.2f}%\".format(accuracy*100))\n",
        "    # print the confusion matrix\n",
        "    print(confusion_matrix(y_test, y_pred))\n",
        "    # conf_mat = confusion_matrix(y_test, y_pred)\n",
        "    # sns.heatmap(conf_mat, square=True, annot=True, cmap='Blues', fmt='d', cbar=False)\n",
        "    # sns_plot.figure.savefig(f\"knn_conf_matrix_{img_name}.png\")\n",
        "\n",
        "    # print the classification report\n",
        "    # print(classification_report(y_test, y_pred))\n",
        "    return True\n",
        "\n",
        "'''import and fit Gaussian Naive bayes model'''\n",
        "def gaussian_naive_bayes(X, y,img_name=\"def\"):\n",
        "    '''\n",
        "    X is a numpy.ndarray of shape (n, d) containing the dataset\n",
        "    y is a numpy.ndarray of shape (n, 1) containing the labels of the data\n",
        "    '''\n",
        "    # split the data into training and testing sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4,\n",
        "                                                        random_state=0,shuffle=True)\n",
        "    # instantiate the model\n",
        "    gnb = GaussianNB()\n",
        "    # fit the model\n",
        "    gnb.fit(X_train, y_train.ravel())\n",
        "    # predict the labels of the testing set\n",
        "    y_pred = gnb.predict(X_test)\n",
        "    # calculate the accuracy of the model\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    # print the accuracy of the model\n",
        "    print(\"Accuracy: {:.2f}%\".format(accuracy*100))\n",
        "    # print the confusion matrix\n",
        "    conf_mat = confusion_matrix(y_test, y_pred)\n",
        "    # sns.heatmap(conf_mat, square=True, annot=True, cmap='Blues', fmt='d', cbar=False)\n",
        "    # sns_plot.figure.savefig(f\"gaussian_naive_conf_matrix_{img_name}.png\")\n",
        "    # print the classification report\n",
        "    # print(classification_report(y_test, y_pred))\n",
        "    return None\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qoCgVcMmmSNn"
      },
      "source": [
        "def load_data(file1,file2):\n",
        "  names = ['user_id', 'item_id', 'rating', 'timestamp']\n",
        "  data= pd.read_csv(file1,delim_whitespace=True,names=names)\n",
        "  data2 = pd.read_csv(file2,delim_whitespace=True,names=names)\n",
        "  return data,data2\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K4zk4zt-m2en"
      },
      "source": [
        "# change file location according to attack type and size\n",
        "names = ['user_id', 'item_id', 'rating', 'timestamp']\n",
        "ratings=pd.read_csv(\"/content/drive/MyDrive/attack_datasets/Movielens1M/random/random_profiles_1.0.txt\",delim_whitespace=True,names=names)\n",
        "names1=['user_id','label']\n",
        "labels=pd.read_csv(\"/content/drive/MyDrive/attack_datasets/Movielens1M/random/random_labels_1.0.txt\",delim_whitespace=True,names=names1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data matrix, timestamp matrix\n",
        "n_users = ratings.user_id.unique().shape[0]\n",
        "n_items = ratings.item_id.unique().shape[0]\n",
        "n_items = ratings['item_id'].max()\n",
        "data_matrix = np.zeros((n_users,n_items))\n",
        "#timestamp_matrix=np.zeros((n_users,n_items))\n",
        "for line in ratings.itertuples():\n",
        "    data_matrix[line[1]-1,line[2]-1] = line[3]\n",
        "    #timestamp_matrix[line[1]-1,line[2]-1] = line[4]\n",
        "print(\"Original rating matrix : \",data_matrix.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uFmbY0m6xa4q",
        "outputId": "20c6a61e-f4b1-42c8-fa87-0cfd3aba32f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original rating matrix :  (6643, 3952)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "creating labels for genuine and attack profiles according to the attack percentage (10/15/20/25%)\n",
        "'''\n",
        "labels_new = [1 for i in range(0,6040)] + [0 for i in range((labels.shape[0]-1)-6040)]"
      ],
      "metadata": {
        "id": "eYxYJakXzIc3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = labels_new\n",
        "X = data_matrix"
      ],
      "metadata": {
        "id": "TgwCM80-0fhv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TcduG10Btzdf",
        "outputId": "3074d71d-716d-46a8-b90c-b6943751c474"
      },
      "source": [
        "knn = knn_classifier(X,np.array(y),\"knn\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 91.65%\n",
            "[[   0  222]\n",
            " [   0 2436]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BBNP7MECxKP-",
        "outputId": "48c1e44e-cf3a-4aa4-a173-9f336c477d8c"
      },
      "source": [
        "logistic_regression(X,np.array(y))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 100.00%\n",
            "[[ 121    0]\n",
            " [   0 2416]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMNawauuxRHf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47e7cc8f-0174-4b77-b6d0-aeadd90b30d6"
      },
      "source": [
        "svm_classifier(X,np.array(y))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 100.00%\n",
            "[[ 468    0]\n",
            " [   0 2431]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ArOa0lzqxTdW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9cc84058-66a3-40b1-f5ca-b61ef5afffe0"
      },
      "source": [
        "random_forest(X,np.array(y))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 100.00%\n",
            "[[ 121    0]\n",
            " [   0 2416]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RvShObVGxGhW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da0f9b25-68f8-4bac-e879-5d270d85744f"
      },
      "source": [
        "sgd_classifier(X,np.array(y))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 100.00%\n",
            "[[ 121    0]\n",
            " [   0 2416]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1UEBn1mhxeGe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "614e31ec-fff9-4b59-da17-ec4dfe8226b9"
      },
      "source": [
        "gaussian_naive_bayes(X,np.array(y))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 95.75%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pandas import read_csv\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "import numpy as np\n",
        "# load dataset\n",
        "import pandas as pd\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "def create_MLP_baseline():\n",
        "  # create model\n",
        "  model = Sequential()\n",
        "  model.add(Dense(400, input_dim=3952, activation='relu'))\n",
        "  model.add(Dense(200,activation='relu'))\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(Dense(100, activation='relu'))\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(Dense(10))\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  return model\n",
        "\n",
        "def pipeline(X,y):\n",
        "  \n",
        "    model = create_MLP_baseline()\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4,\n",
        "                                                        random_state=0,shuffle=True)    \n",
        "    history = model.fit(X_train,np.array(y_train),epochs=1)\n",
        "    results = model.evaluate(X_test,np.array(y_test))\n",
        "    return results[1]"
      ],
      "metadata": {
        "id": "Lug0f6wLDVhH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline(X,y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fLC_oDmYDXQy",
        "outputId": "8425d753-9830-408d-a709-04b017f23cdc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "119/119 [==============================] - 2s 14ms/step - loss: 0.0371 - accuracy: 0.9874\n",
            "80/80 [==============================] - 1s 5ms/step - loss: 2.1188e-05 - accuracy: 1.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    }
  ]
}